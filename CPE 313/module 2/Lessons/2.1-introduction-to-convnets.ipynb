{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"a2TifoVE22uc","executionInfo":{"status":"ok","timestamp":1648042620693,"user_tz":-480,"elapsed":2427,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"988e87a6-8a35-4210-db2a-541d2eeff75f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["import keras\n","keras.__version__"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"MSqt1tsS22ui","executionInfo":{"status":"ok","timestamp":1648044200931,"user_tz":-480,"elapsed":481,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}}},"outputs":[],"source":["from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))"]},{"cell_type":"markdown","metadata":{"id":"aVuwpyKt22uk"},"source":["Let's display the architecture of our convnet so far:"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtfPWdeG22uo","executionInfo":{"status":"ok","timestamp":1648044202122,"user_tz":-480,"elapsed":7,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"50fb829b-9c79-4b55-e889-23b49a7afc9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 3, 3, 64)          36928     \n","                                                                 \n","=================================================================\n","Total params: 55,744\n","Trainable params: 55,744\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"J2fyghyk22up"},"source":["You can see above that the output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width \n","and height dimensions tend to shrink as we go deeper in the network. The number of channels is controlled by the first argument passed to \n","the `Conv2D` layers (e.g. 32 or 64).\n","\n","The next step would be to feed our last output tensor (of shape `(3, 3, 64)`) into a densely-connected classifier network like those you are \n","already familiar with: a stack of `Dense` layers. These classifiers process vectors, which are 1D, whereas our current output is a 3D tensor. \n","So first, we will have to flatten our 3D outputs to 1D, and then add a few `Dense` layers on top:"]},{"cell_type":"code","execution_count":49,"metadata":{"collapsed":true,"id":"NMkTALKG22uq","executionInfo":{"status":"ok","timestamp":1648044204819,"user_tz":-480,"elapsed":3,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}}},"outputs":[],"source":["model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))"]},{"cell_type":"markdown","metadata":{"id":"vyH-tLuR22ur"},"source":["We are going to do 10-way classification, so we use a final layer with 10 outputs and a softmax activation. Now here's what our network \n","looks like:"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lB5Ro9Ij22vL","executionInfo":{"status":"ok","timestamp":1648044207449,"user_tz":-480,"elapsed":500,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"7c6a9634-110b-4343-a7c0-ef377b22b24a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_16 (Conv2D)          (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n"," g2D)                                                            \n","                                                                 \n"," conv2d_17 (Conv2D)          (None, 3, 3, 64)          36928     \n","                                                                 \n"," flatten_7 (Flatten)         (None, 576)               0         \n","                                                                 \n"," dense_14 (Dense)            (None, 64)                36928     \n","                                                                 \n"," dense_15 (Dense)            (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"r0x4rUP622vM"},"source":["As you can see, our `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two `Dense` layers.\n","\n","Now, let's train our convnet on the MNIST digits. We will reuse a lot of the code we have already covered in the MNIST example from Chapter \n","2."]},{"cell_type":"code","execution_count":51,"metadata":{"id":"TXKXpQ7822vN","executionInfo":{"status":"ok","timestamp":1648044212169,"user_tz":-480,"elapsed":888,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}}},"outputs":[],"source":["from keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype('float32') / 255\n","\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype('float32') / 255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkuaCOmc22vN","executionInfo":{"status":"ok","timestamp":1648044825056,"user_tz":-480,"elapsed":293624,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"e468e95f-4709-4321-d2d4-17f92cd1847a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/7\n","600/600 [==============================] - 43s 70ms/step - loss: 0.0939 - accuracy: 0.9714\n","Epoch 2/7\n","600/600 [==============================] - 42s 70ms/step - loss: 0.0532 - accuracy: 0.9837\n","Epoch 3/7\n","600/600 [==============================] - 42s 70ms/step - loss: 0.0370 - accuracy: 0.9880\n","Epoch 4/7\n","600/600 [==============================] - 42s 70ms/step - loss: 0.0285 - accuracy: 0.9909\n","Epoch 5/7\n","600/600 [==============================] - 42s 70ms/step - loss: 0.0230 - accuracy: 0.9926\n","Epoch 6/7\n","600/600 [==============================] - 42s 69ms/step - loss: 0.0180 - accuracy: 0.9940\n","Epoch 7/7\n","600/600 [==============================] - 42s 69ms/step - loss: 0.0163 - accuracy: 0.9942\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f548b433a90>"]},"metadata":{},"execution_count":56}],"source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(train_images, train_labels, epochs=7, batch_size=100)"]},{"cell_type":"markdown","metadata":{"id":"NkwTTMBJ22vO"},"source":["Let's evaluate the model on the test data:"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrxagQVm22vP","executionInfo":{"status":"ok","timestamp":1648045356072,"user_tz":-480,"elapsed":2675,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"64597ce9-5d40-44c3-d4e3-cc535414441f"},"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 3s 8ms/step - loss: 0.0379 - accuracy: 0.9890\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zw8pbUrV22vQ","executionInfo":{"status":"ok","timestamp":1648045358900,"user_tz":-480,"elapsed":365,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"74b97624-2479-4824-b083-1e7dd1041359"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9890000224113464"]},"metadata":{},"execution_count":58}],"source":["test_acc"]},{"cell_type":"code","source":["test_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sLZ73oh49Zo","executionInfo":{"status":"ok","timestamp":1648045360758,"user_tz":-480,"elapsed":328,"user":{"displayName":"JOHN EDWARD BINAY","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06007375553971461223"}},"outputId":"81053c15-8fb6-4d88-9fa2-7eaca240c5a1"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.037858348339796066"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"nbEB8PnE22vQ"},"source":["While our densely-connected network from Chapter 2 had a test accuracy of 97.8%, our basic convnet has a test accuracy of 99.3%: we \n","decreased our error rate by 68% (relative). Not bad! "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"2.1-introduction-to-convnets.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}